<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="TensorFlow中的子模块 tf.keras中快速构建神经网络的高层接口">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow中Keras 高层接口">
<meta property="og:url" content="http://yoursite.com/2020/12/04/Tensorflow-Keras-high-level-interface/index.html">
<meta property="og:site_name" content="ccclll777&#39;s blogs">
<meta property="og:description" content="TensorFlow中的子模块 tf.keras中快速构建神经网络的高层接口">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-12-04T05:41:13.000Z">
<meta property="article:modified_time" content="2020-12-04T07:58:06.000Z">
<meta property="article:author" content="ccclll777">
<meta property="article:tag" content="python">
<meta property="article:tag" content="深度学习框架">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2020/12/04/Tensorflow-Keras-high-level-interface/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Tensorflow中Keras 高层接口 | ccclll777's blogs</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="ccclll777's blogs" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
<a href="https://github.com/ccclll777" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">ccclll777's blogs</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/04/Tensorflow-Keras-high-level-interface/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="ccclll777">
      <meta itemprop="description" content="胸怀猛虎 细嗅蔷薇">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ccclll777's blogs">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Tensorflow中Keras 高层接口
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-12-04 13:41:13 / 修改时间：15:58:06" itemprop="dateCreated datePublished" datetime="2020-12-04T13:41:13+08:00">2020-12-04</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>9 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>TensorFlow中的子模块 tf.keras中快速构建神经网络的高层接口</p>
<a id="more"></a>

<h1 id="常见功能模块"><a href="#常见功能模块" class="headerlink" title="常见功能模块"></a>常见功能模块</h1><p><strong>Keras 提供了一系列高层的神经网络相关类和函数，如经典数据集加载函数、网络层类、模型容器、损失函数类、优化器类、经典模型类。</strong></p>
<h2 id="常见网络层类"><a href="#常见网络层类" class="headerlink" title="常见网络层类"></a>常见网络层类</h2><ul>
<li>对于常见的神经网络层，可以使用张量方式的底层接口函数来实现，这些接口函数一 般在 tf.nn 模块中</li>
<li>对于常见的网络层，我们一般直接使用层方式来完成模型的 搭建，在 tf.keras.layers 命名空间中提供了大量常见网络层的类，如全连接层、激活函数层、池化层、卷积层、循环神经网络层。</li>
<li>例如以 Softmax 层为例，它既可以使用 tf.nn.softmax 函数在前向传播逻辑中完成 Softmax 运算，也可以通过 layers.Softmax(axis)类搭建 Softmax 网络层<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 导入keras模型，不能使用import keras，它导入的是标准的Keras库 </span></span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers <span class="comment"># 导入常见网络层类</span></span><br><span class="line"><span class="comment">#然后创建 Softmax 层，并调用__call__方法完成前向计算</span></span><br><span class="line">x = tf.constant([<span class="number">2.</span>,<span class="number">1.</span>,<span class="number">0.1</span>]) <span class="comment"># 创建输入张量 layer = layers.Softmax(axis=-1) # 创建Softmax层</span></span><br><span class="line">out = layer(x) <span class="comment"># 调用softmax前向计算，输出为out</span></span><br><span class="line"><span class="comment">#可以直接通过 tf.nn.softmax()函数完成计算</span></span><br><span class="line">out = tf.nn.softmax(x) <span class="comment"># 调用 softmax 函数完成前向计算</span></span><br></pre></td></tr></table></figure>
<h2 id="网络容器"><a href="#网络容器" class="headerlink" title="网络容器"></a>网络容器</h2>为了避免当网络层数较深时，手动调用每一层的类实例完成前向传播运算的麻烦。</li>
<li>可以通过 Keras 提供的网络容器 Sequential 将多个<br>网络层封装成一个大网络模型，只需要调用网络模型的实例一次即可完成数据从第一层到 最末层的顺序传播运算。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入Sequential容器</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras </span><br><span class="line"><span class="keyword">import</span> layers, Sequential </span><br><span class="line">network = Sequential([ <span class="comment"># 封装为一个网络</span></span><br><span class="line">layers.Dense(<span class="number">3</span>, activation=<span class="literal">None</span>), <span class="comment"># 全连接层，此处不使用激活函数 layers.ReLU(),#激活函数层</span></span><br><span class="line">layers.Dense(<span class="number">2</span>, activation=<span class="literal">None</span>), <span class="comment"># 全连接层，此处不使用激活函数</span></span><br><span class="line">layers.ReLU() <span class="comment">#激活函数层 </span></span><br><span class="line">])</span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">3</span>])</span><br><span class="line">out = network(x) <span class="comment"># 输入从第一层开始，逐层传播至输出层，并返回输出层的输出</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Sequential 容器也可以通过 add()方法继续追加新的网络层，实现动态创建网络的功能</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">layers_num = <span class="number">2</span> <span class="comment"># 堆叠2次</span></span><br><span class="line">network = Sequential([]) <span class="comment"># 先创建空的网络容器 for _ in range(layers_num):</span></span><br><span class="line">network.add(layers.Dense(<span class="number">3</span>)) <span class="comment"># 添加全连接层</span></span><br><span class="line">network.add(layers.ReLU())<span class="comment"># 添加激活函数层 </span></span><br><span class="line"><span class="comment">#通过调用类的 build 方法并指定 输入大小，即可自动创建所有层的内部张量</span></span><br><span class="line">network.build(input_shape=(<span class="number">4</span>, <span class="number">4</span>)) <span class="comment"># 创建网络参数  </span></span><br><span class="line">network.summary()</span><br></pre></td></tr></table></figure>

<ul>
<li>当我们通过 Sequential 容量封装多个网络层时，每层的参数列表将会自动并入 Sequential 容器的参数列表中，不需要人为合并网络参数列表。Sequential 对象的 trainable_variables 和 variables 包含了所有层的待优化张量列表 和全部张量列表。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印网络的待优化参数名与shape</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> network.trainable_variables: </span><br><span class="line">	print(p.name, p.shape) <span class="comment"># 参数名和形状</span></span><br></pre></td></tr></table></figure>
<h1 id="模型装配、训练与测试"><a href="#模型装配、训练与测试" class="headerlink" title="模型装配、训练与测试"></a>模型装配、训练与测试</h1><h2 id="模型装配"><a href="#模型装配" class="headerlink" title="模型装配"></a>模型装配</h2><ul>
<li><p>在 Keras 中，有 2 个比较特殊的类:keras.Model 和 keras.layers.Layer 类。</p>
</li>
<li><p>Layer 类是网络层的母类，定义了网络层的一些常见功能，如添加权值、管理权值列表等。</p>
</li>
<li><p>Model 类是网络的母类，除了具有 Layer 类的功能，还添加了保存模型、加载模型、训练与测试模型等便捷功能。</p>
</li>
<li><p>Sequential也是 Model 的子类，因此具有 Model 类的所有功能。</p>
</li>
<li><p>创建5层的全连接网络</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建5层的全连接网络</span></span><br><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">                 layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">                 layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">                 layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="number">4</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br></pre></td></tr></table></figure>

<ul>
<li>Keras 中提供了 compile()和 fit()函数，创建网络后，正常的流程是循环迭代数据集多个 Epoch，每次按批产生训练数据、前向计 算，然后通过损失函数计算误差值，并反向传播自动计算梯度、更新网络参数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入优化器，损失函数模块</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers,losses </span><br><span class="line"><span class="comment"># 模型装配</span></span><br><span class="line"><span class="comment"># 采用Adam优化器，学习率为0.01;采用交叉熵损失函数，包含Softmax </span></span><br><span class="line">network.compile(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">'accuracy'</span>] <span class="comment"># 设置测量指标为准确率 )</span></span><br></pre></td></tr></table></figure>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><ul>
<li>模型装配完成后，即可通过 fit()函数送入待训练的数据集和验证用的数据集</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定训练集为train_db，验证集为val_db,训练5个epochs，每2个epoch验证一次 # 返回训练轨迹信息保存在history对象中</span></span><br><span class="line">history = network.fit(train_db, epochs=<span class="number">5</span>, validation_data=val_db,</span><br><span class="line">validation_freq=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p> train_db 为 tf.data.Dataset 对象，也可以传入 Numpy Array 类型的数据;epochs 参数指 定训练迭代的 Epoch 数量;validation_data 参数指定用于验证(测试)的数据集和验证的频率 validation_freq</p>
<ul>
<li>fit 函数会返回训练过程的数据记录 history，其中 history.history 为字典对象，包含了训练过程中的 loss、测量指标等记录项</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history.history <span class="comment"># 打印训练记录</span></span><br></pre></td></tr></table></figure>
<p>fit()函数的运行代表了网络的训练过程，因此会消耗相当的训练时间，并在训练结束 后才返回，训练中产生的历史数据可以通过返回值对象取得。</p>
<h2 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h2><ul>
<li>通过 Model.predict(x)方法即可完成模型的预测</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载一个 batch 的测试数据</span></span><br><span class="line">x,y = next(iter(db_test))</span><br><span class="line">print(<span class="string">'predict x:'</span>, x.shape) <span class="comment"># 打印当前batch的形状</span></span><br><span class="line">out = network.predict(x) <span class="comment"># 模型预测，预测结果保存在out中</span></span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure>

<ul>
<li>如果只是简单的测试模型的性能，可以通过 Model.evaluate(db)循环测试完 db 数据集 上所有样本，并打印出性能指标</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.evaluate(db_test) <span class="comment"># 模型测试，测试在db_test上的性能表现</span></span><br></pre></td></tr></table></figure>
<h1 id="模型保存与加载"><a href="#模型保存与加载" class="headerlink" title="模型保存与加载"></a>模型保存与加载</h1><p>模型训练完成后，需要将模型保存到文件系统上，从而方便后续的模型测试与部署工作。</p>
<h2 id="张量方式"><a href="#张量方式" class="headerlink" title="张量方式"></a>张量方式</h2><ul>
<li>通过调用 Model.save_weights(path)方法即可将当前的 网络参数保存到 path 文件上<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.save_weights(<span class="string">'weights.ckpt'</span>) <span class="comment"># 保存模型的所有张量数据</span></span><br></pre></td></tr></table></figure>
将 network 模型保存到 weights.ckpt 文件上。</li>
<li>在需要的时候，先创建好网络对象， 然后调用网络对象的 load_weights(path)方法即可将指定的模型文件中保存的张量数值写入 到当前网络参数中去</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型参数到文件上 </span></span><br><span class="line">network.save_weights(<span class="string">'weights.ckpt'</span>) </span><br><span class="line">print(<span class="string">'saved weights.'</span>)</span><br><span class="line"><span class="keyword">del</span> network <span class="comment"># 删除网络对象</span></span><br><span class="line"><span class="comment"># 重新创建相同的网络结构</span></span><br><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.compile(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">        loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">        metrics=[<span class="string">'accuracy'</span>]</span><br><span class="line">   )</span><br><span class="line"><span class="comment"># 从参数文件中读取数据并写入当前网络 </span></span><br><span class="line">network.load_weights(<span class="string">'weights.ckpt'</span>)</span><br><span class="line">print(<span class="string">'loaded weights!'</span>)</span><br></pre></td></tr></table></figure>

<h2 id="网络方式"><a href="#网络方式" class="headerlink" title="网络方式"></a>网络方式</h2><ul>
<li>通过 Model.save(path)函数可以将模型的结构以及模型的参数保存到 path 文件上，在不 需要网络源文件的条件下，通过 keras.models.load_model(path)即可恢复网络结构和网络参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型结构与模型参数到文件</span></span><br><span class="line">network.save(<span class="string">'model.h5'</span>)</span><br><span class="line">print(<span class="string">'saved total model.'</span>)</span><br><span class="line"><span class="keyword">del</span> network <span class="comment"># 删除网络对象</span></span><br></pre></td></tr></table></figure>

<ul>
<li>通过 model.h5 文件即可恢复出网络的结构和状态，不需要提前创建网络对象</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 从文件恢复网络结构与网络参数</span></span><br><span class="line">network = keras.models.load_model(<span class="string">'model.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>model.h5 文件除了保存了模型参数外，还应保存了网络结构信息，不需要提前 创建模型即可直接从文件中恢复出网络 network 对象</p>
<h2 id="SavedModel-方式"><a href="#SavedModel-方式" class="headerlink" title="SavedModel 方式"></a>SavedModel 方式</h2><ul>
<li>通过 tf.saved_model.save (network, path)即可将模型以 SavedModel 方式保存到 path 目录中</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型结构与模型参数到文件</span></span><br><span class="line">tf.saved_model.save(network, <span class="string">'model-savedmodel'</span>)</span><br><span class="line">print(<span class="string">'saving savedmodel.'</span>)</span><br><span class="line"><span class="keyword">del</span> network <span class="comment"># 删除网络对象</span></span><br></pre></td></tr></table></figure>

<ul>
<li>通过 tf.saved_model.load 函数即可恢复出模型对象，我们在恢复出模型实例后，完成测试准确率的计算</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'load savedmodel from file.'</span>)</span><br><span class="line"><span class="comment"># 从文件恢复网络结构与网络参数</span></span><br><span class="line">network = tf.saved_model.load(<span class="string">'model-savedmodel'</span>) <span class="comment"># 准确率计量器</span></span><br><span class="line">acc_meter = metrics.CategoricalAccuracy()</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> ds_val: <span class="comment"># 遍历测试集</span></span><br><span class="line">pred = network(x) <span class="comment"># 前向计算</span></span><br><span class="line">acc_meter.update_state(y_true=y, y_pred=pred) <span class="comment"># 更新准确率统计 # 打印准确率</span></span><br><span class="line">print(<span class="string">"Test Accuracy:%f"</span> % acc_meter.result())</span><br></pre></td></tr></table></figure>
<h1 id="自定义网络"><a href="#自定义网络" class="headerlink" title="自定义网络"></a>自定义网络</h1><p>对于需要创建自定义逻辑的网络层，可以通过自定义类来实现。在创建自定义网络层 类时，需要继承自 layers.Layer 基类;创建自定义的网络类时，需要继承自 keras.Model 基 类，这样建立的自定义类才能够方便的利用 Layer/Model 基类提供的参数管理等功能，同 时也能够与其他的标准网络层类交互使用。</p>
<h2 id="自定义网络层"><a href="#自定义网络层" class="headerlink" title="自定义网络层"></a>自定义网络层</h2><ul>
<li>对于自定义的网络层，至少需要实现初始化<strong>init</strong>方法和前向传播逻辑 call 方法。</li>
<li>首先创建类，并继承自 Layer 基类。创建初始化方法，并调用母类的初始化函数，由 于是全连接层，因此需要设置两个参数:输入特征的长度 inp_dim 和输出特征的长度 outp_dim，并通过 self.add_variable(name, shape)创建 shape 大小，名字为 name 的张量𝑾， 并设置为需要优化。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span><span class="params">(layers.Layer)</span>:</span> <span class="comment"># 自定义网络层</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inp_dim, outp_dim)</span>:</span></span><br><span class="line">		super(MyDense, self).__init__()</span><br><span class="line">		<span class="comment"># 创建权值张量并添加到类管理列表中，设置为需要优化</span></span><br><span class="line">		self.kernel = self.add_variable(<span class="string">'w'</span>, [inp_dim, outp_dim],</span><br><span class="line">		trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = MyDense(<span class="number">4</span>,<span class="number">3</span>) <span class="comment"># 创建输入为 4，输出为 3 节点的自定义层 </span></span><br><span class="line">net.variables,net.trainable_variables <span class="comment"># 查看自定义层的参数列表</span></span><br></pre></td></tr></table></figure>

<ul>
<li>通过修改为 self.kernel = self.add_variable(‘w’, [inp_dim, outp_dim], trainable=False)，我们可以设置𝑾张量不需要被优化</li>
<li>通过 tf.Variable 创建的类成员也会自动加入类参数列表</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过 tf.Variable 创建的类成员也会自动加入类参数列表</span></span><br><span class="line">self.kernel = tf.Variable(tf.random.normal([inp_dim, outp_dim]),</span><br><span class="line">                trainable=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>自定义类的前向运算逻辑，对于这个例 子，只需要完成𝑶 = 𝑿@𝑾矩阵运算，并通过固定的 ReLU 激活函数即可</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs, training=None)</span>:</span> </span><br><span class="line">	<span class="comment"># 实现自定义类的前向计算逻辑</span></span><br><span class="line">	<span class="comment"># X@W</span></span><br><span class="line">	out = inputs @ self.kernel</span><br><span class="line">	<span class="comment"># 执行激活函数运算</span></span><br><span class="line">	out = tf.nn.relu(out) <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<ul>
<li>自定义类的前向运算逻辑实现在 call(inputs, training=None)函数中，其中 inputs 代表输入，由用户在调用时传入;training 参数用于指定模型的状态:training 为 True 时执 行训练模式，training 为 False 时执行测试模式，默认参数为 None，即测试模式。由于全连 接层的训练模式和测试模式逻辑一致，此处不需要额外处理。对于部份测试模式和训练模 式不一致的网络层，需要根据 training 参数来设计需要执行的逻辑。</li>
</ul>
<h2 id="自定义网络-1"><a href="#自定义网络-1" class="headerlink" title="自定义网络"></a>自定义网络</h2><ul>
<li>自定义网络类可以和其他标准类一样，通过 Sequential 容器方便地封装成一个网络模型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([MyDense(<span class="number">784</span>, <span class="number">256</span>), <span class="comment"># 使用自定义的层 MyDense(256, 128),</span></span><br><span class="line">                 MyDense(<span class="number">128</span>, <span class="number">64</span>),</span><br><span class="line">                 MyDense(<span class="number">64</span>, <span class="number">32</span>),</span><br><span class="line">                 MyDense(<span class="number">32</span>, <span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br></pre></td></tr></table></figure>

<ul>
<li>创建自定义网络类，首先 创建类，并继承自 Model 基类，分别创建对应的网络层对象和前向运算逻辑</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span><span class="params">(keras.Model)</span>:</span></span><br><span class="line">	<span class="comment"># 自定义网络类，继承自 Model 基类 </span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		super(MyModel, self).__init__() <span class="comment"># 完成网络内需要的网络层的创建工作 </span></span><br><span class="line">		self.fc1 = MyDense(<span class="number">28</span>*<span class="number">28</span>, <span class="number">256</span>) </span><br><span class="line">		self.fc2 = MyDense(<span class="number">256</span>, <span class="number">128</span>) </span><br><span class="line">		self.fc3 = MyDense(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">		self.fc4 = MyDense(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">		self.fc5 = MyDense(<span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs, training=None)</span>:</span> <span class="comment"># 自定义前向运算逻辑</span></span><br><span class="line">		x = self.fc1(inputs)</span><br><span class="line">		x = self.fc2(x)</span><br><span class="line">		x = self.fc3(x)</span><br><span class="line">		x = self.fc4(x)</span><br><span class="line">		x = self.fc5(x)</span><br><span class="line">		<span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h1 id="常用模型"><a href="#常用模型" class="headerlink" title="常用模型"></a>常用模型</h1><p>对于常用的网络模型，如 ResNet、VGG 等，不需要手动创建网络，可以直接从 keras.applications 子模块中通过一行代码即可创建并使用这些经典模型，同时还可以通过设 置 weights 参数加载预训练的网络参数。</p>
<h2 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h2><ul>
<li>以 ResNet50 网络模型为例，一般将 ResNet50 去除最后一层后的网络作为新任务的特 征提取子网络，即利用在 ImageNet 数据集上预训练好的网络参数初始化，并根据自定义任 务的类别追加一个对应数据类别数的全连接分类层或子网络，从而可以在预训练网络的基 础上快速、高效地学习新任务。</li>
<li>首先利用 Keras 模型乐园加载 ImageNet 预训练好的 ResNet50 网络</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载 ImageNet 预训练网络模型，并去掉最后一层</span></span><br><span class="line">resnet = keras.applications.ResNet50(weights=<span class="string">'imagenet'</span>,include_top=<span class="literal">False</span>) resnet.summary()</span><br><span class="line"><span class="comment"># 测试网络的输出</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>])</span><br><span class="line">out = resnet(x) <span class="comment"># 获得子网络的输出</span></span><br><span class="line">out.shape</span><br></pre></td></tr></table></figure>

<ul>
<li>新建一个池化层(这里的池化层暂时 可以理解为高、宽维度下采样的功能)，将特征从[𝑏, 7,7,2048]降维到[𝑏, 2048]</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建池化层</span></span><br><span class="line">global_average_layer = layers.GlobalAveragePooling2D() <span class="comment"># 利用上一层的输出作为本层的输入，测试其输出</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">7</span>,<span class="number">7</span>,<span class="number">2048</span>])</span><br><span class="line"><span class="comment"># 池化层降维，形状由[4,7,7,2048]变为[4,1,1,2048],删减维度后变为[4,2048] </span></span><br><span class="line">out = global_average_layer(x)</span><br><span class="line">print(out.shape)</span><br></pre></td></tr></table></figure>

<ul>
<li>新建一个全连接层，并设置输出节点数为 100</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建全连接层</span></span><br><span class="line">fc = layers.Dense(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 利用上一层的输出[4,2048]作为本层的输入，测试其输出</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">2048</span>])</span><br><span class="line">out = fc(x) <span class="comment"># 输出层的输出为样本属于 100 类别的概率分布</span></span><br><span class="line">print(out.shape)</span><br></pre></td></tr></table></figure>

<h1 id="测量工具"><a href="#测量工具" class="headerlink" title="测量工具"></a>测量工具</h1><p>在网络的训练过程中，经常需要统计准确率、召回率等测量指标，除了可以通过手动 计算的方式获取这些统计数据外，Keras 提供了一些常用的测量工具，位于 keras.metrics 模 块中，专门用于统计训练过程中常用的指标数据。</p>
<h2 id="新建测量器"><a href="#新建测量器" class="headerlink" title="新建测量器"></a>新建测量器</h2><p>在 keras.metrics 模块中，提供了较多的常用测量器类，如统计平均值的 Mean 类，统 计准确率的 Accuracy 类，统计余弦相似度的 CosineSimilarity 类等。下面我们以统计误差 值为例。在前向运算时，我们会得到每一个 Batch 的平均误差，但是我们希望统计每个 Step 的平均误差，因此选择使用 Mean 测量器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建平均测量器，适合 Loss 数据 </span></span><br><span class="line">loss_meter = metrics.Mean()</span><br></pre></td></tr></table></figure>
<h2 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h2><p>通过测量器的 update_state 函数可以写入新的数据，测量器会根据自身逻辑记录并处理采样数据。例如，在每个 Step 结束时采集一次 loss 值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 记录采样的数据，通过 float()函数将张量转换为普通数值</span></span><br><span class="line">loss_meter.update_state(float(loss))</span><br></pre></td></tr></table></figure>
<h2 id="读取统计信息"><a href="#读取统计信息" class="headerlink" title="读取统计信息"></a>读取统计信息</h2><p>在采样多次数据后，可以选择在需要的地方调用测量器的 result()函数，来获取统计值。例如，间隔性统计 loss 均值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 打印统计期间的平均 loss</span></span><br><span class="line">print(step, <span class="string">'loss:'</span>, loss_meter.result())</span><br></pre></td></tr></table></figure>
<h2 id="清除状态"><a href="#清除状态" class="headerlink" title="清除状态"></a>清除状态</h2><p>由于测量器会统计所有历史记录的数据，因此在启动新一轮统计时，有必要清除历史 状态。通过 reset_states()即可实现清除状态功能。例如，在每次读取完平均误差后，清零统 计信息，以便下一轮统计的开始。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">	<span class="comment"># 打印统计的平均 loss</span></span><br><span class="line">	print(step, <span class="string">'loss:'</span>, loss_meter.result())</span><br><span class="line">	loss_meter.reset_states() <span class="comment"># 打印完后，清零测量器</span></span><br></pre></td></tr></table></figure>
<h2 id="准确率统计实战"><a href="#准确率统计实战" class="headerlink" title="准确率统计实战"></a>准确率统计实战</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">acc_meter = metrics.Accuracy() <span class="comment"># 创建准确率测量器</span></span><br><span class="line"><span class="comment"># [b, 784] =&gt; [b, 10]，网络输出值</span></span><br><span class="line"><span class="comment">#Accuracy 类的 update_state 函数的参数为预测值和真实值，而不是当前 Batch 的准确率</span></span><br><span class="line">out = network(x)</span><br><span class="line"><span class="comment"># [b, 10] =&gt; [b]，经过 argmax 后计算预测值 </span></span><br><span class="line">pred = tf.argmax(out, axis=<span class="number">1</span>)</span><br><span class="line">pred = tf.cast(pred, dtype=tf.int32) <span class="comment"># 根据预测值与真实值写入测量器</span></span><br><span class="line">acc_meter.update_state(y, pred)</span><br><span class="line"><span class="comment"># 读取统计结果</span></span><br><span class="line">print(step, <span class="string">'Evaluate Acc:'</span>, acc_meter.result().numpy()) </span><br><span class="line">acc_meter.reset_states() <span class="comment"># 清零测量器</span></span><br></pre></td></tr></table></figure>
<h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><p>TensorFlow 提供了一个专门的可视 化工具，叫做 TensorBoard，它通过 TensorFlow 将监控数据写入到文件系统，并利用 Web 后端监控对应的文件目录，从而可以允许用户从远程查看网络的监控数据。</p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><ul>
<li>通过 tf.summary.create_file_writer 创建监控对象类实例，并指定监控数据的写入目录</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 创建监控类，监控数据将写入 log_dir 目录</span></span><br><span class="line">summary_writer = tf.summary.create_file_writer(log_dir)</span><br></pre></td></tr></table></figure>

<ul>
<li>通过 tf.summary.scalar 函数记录监控数据，并指定时 间戳 step 参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> summary_writer.as_default(): <span class="comment"># 写入环境</span></span><br><span class="line"><span class="comment"># 当前时间戳 step 上的数据为 loss，写入到名为 train-loss 数据库中</span></span><br><span class="line">   tf.summary.scalar(<span class="string">'train-loss'</span>, float(loss), step=step)</span><br></pre></td></tr></table></figure>

<ul>
<li>通过 tf.summary.image 函数写入监控图片数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> summary_writer.as_default():<span class="comment"># 写入环境</span></span><br><span class="line"><span class="comment"># 写入测试准确率</span></span><br><span class="line">	tf.summary.scalar(<span class="string">'test-acc'</span>, float(total_correct/total),</span><br><span class="line">	step=step)</span><br><span class="line"><span class="comment"># 可视化测试用的图片，设置最多可视化 9 张图片</span></span><br><span class="line">	tf.summary.image(<span class="string">"val-onebyone-images:"</span>, val_images,</span><br><span class="line">max_outputs=<span class="number">9</span>, step=step)</span><br></pre></td></tr></table></figure>
    </div>

    
    
    
<div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
  
</div>

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i></a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/" rel="tag"><i class="fa fa-tag"></i></a>
              <a href="/tags/tensorflow/" rel="tag"><i class="fa fa-tag"></i></a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/12/04/Tensorflow-and-Neural-Networks/" rel="prev" title="Tensorflow构建简单神经网络">
      <i class="fa fa-chevron-left"></i> Tensorflow构建简单神经网络
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/12/04/Tensorflow-and-Convolutional-Neural-Network/" rel="next" title="Tensorflow与卷积神经网络">
      Tensorflow与卷积神经网络 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#常见功能模块"><span class="nav-number">1.</span> <span class="nav-text">常见功能模块</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#常见网络层类"><span class="nav-number">1.1.</span> <span class="nav-text">常见网络层类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络容器"><span class="nav-number">1.2.</span> <span class="nav-text">网络容器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型装配、训练与测试"><span class="nav-number">2.</span> <span class="nav-text">模型装配、训练与测试</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#模型装配"><span class="nav-number">2.1.</span> <span class="nav-text">模型装配</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型训练"><span class="nav-number">2.2.</span> <span class="nav-text">模型训练</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型测试"><span class="nav-number">2.3.</span> <span class="nav-text">模型测试</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型保存与加载"><span class="nav-number">3.</span> <span class="nav-text">模型保存与加载</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#张量方式"><span class="nav-number">3.1.</span> <span class="nav-text">张量方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络方式"><span class="nav-number">3.2.</span> <span class="nav-text">网络方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SavedModel-方式"><span class="nav-number">3.3.</span> <span class="nav-text">SavedModel 方式</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#自定义网络"><span class="nav-number">4.</span> <span class="nav-text">自定义网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#自定义网络层"><span class="nav-number">4.1.</span> <span class="nav-text">自定义网络层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自定义网络-1"><span class="nav-number">4.2.</span> <span class="nav-text">自定义网络</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#常用模型"><span class="nav-number">5.</span> <span class="nav-text">常用模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#加载模型"><span class="nav-number">5.1.</span> <span class="nav-text">加载模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#测量工具"><span class="nav-number">6.</span> <span class="nav-text">测量工具</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#新建测量器"><span class="nav-number">6.1.</span> <span class="nav-text">新建测量器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#写入数据"><span class="nav-number">6.2.</span> <span class="nav-text">写入数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#读取统计信息"><span class="nav-number">6.3.</span> <span class="nav-text">读取统计信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#清除状态"><span class="nav-number">6.4.</span> <span class="nav-text">清除状态</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#准确率统计实战"><span class="nav-number">6.5.</span> <span class="nav-text">准确率统计实战</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#可视化"><span class="nav-number">7.</span> <span class="nav-text">可视化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#"><span class="nav-number">7.1.</span> <span class="nav-text"></span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">ccclll777</p>
  <div class="site-description" itemprop="description">胸怀猛虎 细嗅蔷薇</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">43</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/ccclll777" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ccclll777" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:sdu945860882@gmail.com" title="E-Mail → mailto:sdu945860882@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.weibo.com/6732062654" title="Weibo → https:&#x2F;&#x2F;www.weibo.com&#x2F;6732062654" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/baidu_41871794" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;baidu_41871794" rel="noopener" target="_blank"><i class="gratipay fa-fw"></i>CSDN</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ccclll777</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">442k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">6:42</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>



        








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>
    <script defer src="/lib/three/canvas_sphere.min.js"></script>


  















  

  

  

</body>
</html>
