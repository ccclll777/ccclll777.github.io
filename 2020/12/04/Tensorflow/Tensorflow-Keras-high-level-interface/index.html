<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Tensorflow中Keras 高层接口 | ccclll777&#39;s blogs</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="TensorFlow中的子模块 tf.keras中快速构建神经网络的高层接口">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow中Keras 高层接口">
<meta property="og:url" content="http://yoursite.com/2020/12/04/Tensorflow/Tensorflow-Keras-high-level-interface/index.html">
<meta property="og:site_name" content="ccclll777&#39;s blogs">
<meta property="og:description" content="TensorFlow中的子模块 tf.keras中快速构建神经网络的高层接口">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-12-04T05:41:13.000Z">
<meta property="article:modified_time" content="2021-10-16T09:35:29.860Z">
<meta property="article:author" content="ccclll777">
<meta property="article:tag" content="python">
<meta property="article:tag" content="深度学习框架">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="ccclll777&#39;s blogs" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">ccclll777&#39;s blogs</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Tensorflow/Tensorflow-Keras-high-level-interface" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/12/04/Tensorflow/Tensorflow-Keras-high-level-interface/" class="article-date">
  <time datetime="2020-12-04T05:41:13.000Z" itemprop="datePublished">2020-12-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Tensorflow中Keras 高层接口
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>TensorFlow中的子模块 tf.keras中快速构建神经网络的高层接口<br><span id="more"></span></p>
<h1 id="常见功能模块"><a href="#常见功能模块" class="headerlink" title="常见功能模块"></a>常见功能模块</h1><p><strong>Keras 提供了一系列高层的神经网络相关类和函数，如经典数据集加载函数、网络层类、模型容器、损失函数类、优化器类、经典模型类。</strong></p>
<h2 id="常见网络层类"><a href="#常见网络层类" class="headerlink" title="常见网络层类"></a>常见网络层类</h2><ul>
<li>对于常见的神经网络层，可以使用张量方式的底层接口函数来实现，这些接口函数一 般在 tf.nn 模块中</li>
<li>对于常见的网络层，我们一般直接使用层方式来完成模型的 搭建，在 tf.keras.layers 命名空间中提供了大量常见网络层的类，如全连接层、激活函数层、池化层、卷积层、循环神经网络层。</li>
<li>例如以 Softmax 层为例，它既可以使用 tf.nn.softmax 函数在前向传播逻辑中完成 Softmax 运算，也可以通过 layers.Softmax(axis)类搭建 Softmax 网络层<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment"># 导入keras模型，不能使用import keras，它导入的是标准的Keras库 </span></span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers <span class="comment"># 导入常见网络层类</span></span><br><span class="line"><span class="comment">#然后创建 Softmax 层，并调用__call__方法完成前向计算</span></span><br><span class="line">x = tf.constant([<span class="number">2.</span>,<span class="number">1.</span>,<span class="number">0.1</span>]) <span class="comment"># 创建输入张量 layer = layers.Softmax(axis=-1) # 创建Softmax层</span></span><br><span class="line">out = layer(x) <span class="comment"># 调用softmax前向计算，输出为out</span></span><br><span class="line"><span class="comment">#可以直接通过 tf.nn.softmax()函数完成计算</span></span><br><span class="line">out = tf.nn.softmax(x) <span class="comment"># 调用 softmax 函数完成前向计算</span></span><br></pre></td></tr></table></figure>
<h2 id="网络容器"><a href="#网络容器" class="headerlink" title="网络容器"></a>网络容器</h2>为了避免当网络层数较深时，手动调用每一层的类实例完成前向传播运算的麻烦。</li>
<li>可以通过 Keras 提供的网络容器 Sequential 将多个<br>网络层封装成一个大网络模型，只需要调用网络模型的实例一次即可完成数据从第一层到 最末层的顺序传播运算。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入Sequential容器</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras </span><br><span class="line"><span class="keyword">import</span> layers, Sequential </span><br><span class="line">network = Sequential([ <span class="comment"># 封装为一个网络</span></span><br><span class="line">layers.Dense(<span class="number">3</span>, activation=<span class="literal">None</span>), <span class="comment"># 全连接层，此处不使用激活函数 layers.ReLU(),#激活函数层</span></span><br><span class="line">layers.Dense(<span class="number">2</span>, activation=<span class="literal">None</span>), <span class="comment"># 全连接层，此处不使用激活函数</span></span><br><span class="line">layers.ReLU() <span class="comment">#激活函数层 </span></span><br><span class="line">])</span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">3</span>])</span><br><span class="line">out = network(x) <span class="comment"># 输入从第一层开始，逐层传播至输出层，并返回输出层的输出</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Sequential 容器也可以通过 add()方法继续追加新的网络层，实现动态创建网络的功能</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">layers_num = <span class="number">2</span> <span class="comment"># 堆叠2次</span></span><br><span class="line">network = Sequential([]) <span class="comment"># 先创建空的网络容器 for _ in range(layers_num):</span></span><br><span class="line">network.add(layers.Dense(<span class="number">3</span>)) <span class="comment"># 添加全连接层</span></span><br><span class="line">network.add(layers.ReLU())<span class="comment"># 添加激活函数层 </span></span><br><span class="line"><span class="comment">#通过调用类的 build 方法并指定 输入大小，即可自动创建所有层的内部张量</span></span><br><span class="line">network.build(input_shape=(<span class="number">4</span>, <span class="number">4</span>)) <span class="comment"># 创建网络参数  </span></span><br><span class="line">network.summary()</span><br></pre></td></tr></table></figure>
<ul>
<li>当我们通过 Sequential 容量封装多个网络层时，每层的参数列表将会自动并入 Sequential 容器的参数列表中，不需要人为合并网络参数列表。Sequential 对象的 trainable_variables 和 variables 包含了所有层的待优化张量列表 和全部张量列表。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印网络的待优化参数名与shape</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> network.trainable_variables: </span><br><span class="line">	print(p.name, p.shape) <span class="comment"># 参数名和形状</span></span><br></pre></td></tr></table></figure>
<h1 id="模型装配、训练与测试"><a href="#模型装配、训练与测试" class="headerlink" title="模型装配、训练与测试"></a>模型装配、训练与测试</h1><h2 id="模型装配"><a href="#模型装配" class="headerlink" title="模型装配"></a>模型装配</h2><ul>
<li>在 Keras 中，有 2 个比较特殊的类:keras.Model 和 keras.layers.Layer 类。</li>
<li>Layer 类是网络层的母类，定义了网络层的一些常见功能，如添加权值、管理权值列表等。</li>
<li>Model 类是网络的母类，除了具有 Layer 类的功能，还添加了保存模型、加载模型、训练与测试模型等便捷功能。</li>
<li><p>Sequential也是 Model 的子类，因此具有 Model 类的所有功能。</p>
<p>-创建5层的全连接网络</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建5层的全连接网络</span></span><br><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                 layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                 layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                 layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="number">4</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br></pre></td></tr></table></figure>
<ul>
<li>Keras 中提供了 compile()和 fit()函数，创建网络后，正常的流程是循环迭代数据集多个 Epoch，每次按批产生训练数据、前向计 算，然后通过损失函数计算误差值，并反向传播自动计算梯度、更新网络参数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入优化器，损失函数模块</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers,losses </span><br><span class="line"><span class="comment"># 模型装配</span></span><br><span class="line"><span class="comment"># 采用Adam优化器，学习率为0.01;采用交叉熵损失函数，包含Softmax </span></span><br><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>] <span class="comment"># 设置测量指标为准确率 )</span></span><br></pre></td></tr></table></figure>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><ul>
<li>模型装配完成后，即可通过 fit()函数送入待训练的数据集和验证用的数据集</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定训练集为train_db，验证集为val_db,训练5个epochs，每2个epoch验证一次 # 返回训练轨迹信息保存在history对象中</span></span><br><span class="line">history = network.fit(train_db, epochs=<span class="number">5</span>, validation_data=val_db,</span><br><span class="line">validation_freq=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p> train_db 为 tf.data.Dataset 对象，也可以传入 Numpy Array 类型的数据;epochs 参数指 定训练迭代的 Epoch 数量;validation_data 参数指定用于验证(测试)的数据集和验证的频率 validation_freq</p>
<ul>
<li>fit 函数会返回训练过程的数据记录 history，其中 history.history 为字典对象，包含了训练过程中的 loss、测量指标等记录项</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history.history <span class="comment"># 打印训练记录</span></span><br></pre></td></tr></table></figure>
<p>fit()函数的运行代表了网络的训练过程，因此会消耗相当的训练时间，并在训练结束 后才返回，训练中产生的历史数据可以通过返回值对象取得。</p>
<h2 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h2><ul>
<li>通过 Model.predict(x)方法即可完成模型的预测</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载一个 batch 的测试数据</span></span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(db_test))</span><br><span class="line">print(<span class="string">&#x27;predict x:&#x27;</span>, x.shape) <span class="comment"># 打印当前batch的形状</span></span><br><span class="line">out = network.predict(x) <span class="comment"># 模型预测，预测结果保存在out中</span></span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure>
<ul>
<li>如果只是简单的测试模型的性能，可以通过 Model.evaluate(db)循环测试完 db 数据集 上所有样本，并打印出性能指标</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.evaluate(db_test) <span class="comment"># 模型测试，测试在db_test上的性能表现</span></span><br></pre></td></tr></table></figure>
<h1 id="模型保存与加载"><a href="#模型保存与加载" class="headerlink" title="模型保存与加载"></a>模型保存与加载</h1><p>模型训练完成后，需要将模型保存到文件系统上，从而方便后续的模型测试与部署工作。</p>
<h2 id="张量方式"><a href="#张量方式" class="headerlink" title="张量方式"></a>张量方式</h2><ul>
<li>通过调用 Model.save_weights(path)方法即可将当前的 网络参数保存到 path 文件上<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.save_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>) <span class="comment"># 保存模型的所有张量数据</span></span><br></pre></td></tr></table></figure>
将 network 模型保存到 weights.ckpt 文件上。</li>
<li>在需要的时候，先创建好网络对象， 然后调用网络对象的 load_weights(path)方法即可将指定的模型文件中保存的张量数值写入 到当前网络参数中去</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型参数到文件上 </span></span><br><span class="line">network.save_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>) </span><br><span class="line">print(<span class="string">&#x27;saved weights.&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> network <span class="comment"># 删除网络对象</span></span><br><span class="line"><span class="comment"># 重新创建相同的网络结构</span></span><br><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">        loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">        metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">   )</span><br><span class="line"><span class="comment"># 从参数文件中读取数据并写入当前网络 </span></span><br><span class="line">network.load_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;loaded weights!&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="网络方式"><a href="#网络方式" class="headerlink" title="网络方式"></a>网络方式</h2><ul>
<li>通过 Model.save(path)函数可以将模型的结构以及模型的参数保存到 path 文件上，在不 需要网络源文件的条件下，通过 keras.models.load_model(path)即可恢复网络结构和网络参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型结构与模型参数到文件</span></span><br><span class="line">network.save(<span class="string">&#x27;model.h5&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;saved total model.&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> network <span class="comment"># 删除网络对象</span></span><br></pre></td></tr></table></figure>
<ul>
<li>通过 model.h5 文件即可恢复出网络的结构和状态，不需要提前创建网络对象</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 从文件恢复网络结构与网络参数</span></span><br><span class="line">network = keras.models.load_model(<span class="string">&#x27;model.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>model.h5 文件除了保存了模型参数外，还应保存了网络结构信息，不需要提前 创建模型即可直接从文件中恢复出网络 network 对象</p>
<h2 id="SavedModel-方式"><a href="#SavedModel-方式" class="headerlink" title="SavedModel 方式"></a>SavedModel 方式</h2><ul>
<li>通过 tf.saved_model.save (network, path)即可将模型以 SavedModel 方式保存到 path 目录中</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型结构与模型参数到文件</span></span><br><span class="line">tf.saved_model.save(network, <span class="string">&#x27;model-savedmodel&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;saving savedmodel.&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> network <span class="comment"># 删除网络对象</span></span><br></pre></td></tr></table></figure>
<ul>
<li>通过 tf.saved_model.load 函数即可恢复出模型对象，我们在恢复出模型实例后，完成测试准确率的计算</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;load savedmodel from file.&#x27;</span>)</span><br><span class="line"><span class="comment"># 从文件恢复网络结构与网络参数</span></span><br><span class="line">network = tf.saved_model.load(<span class="string">&#x27;model-savedmodel&#x27;</span>) <span class="comment"># 准确率计量器</span></span><br><span class="line">acc_meter = metrics.CategoricalAccuracy()</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> ds_val: <span class="comment"># 遍历测试集</span></span><br><span class="line">pred = network(x) <span class="comment"># 前向计算</span></span><br><span class="line">acc_meter.update_state(y_true=y, y_pred=pred) <span class="comment"># 更新准确率统计 # 打印准确率</span></span><br><span class="line">print(<span class="string">&quot;Test Accuracy:%f&quot;</span> % acc_meter.result())</span><br></pre></td></tr></table></figure>
<h1 id="自定义网络"><a href="#自定义网络" class="headerlink" title="自定义网络"></a>自定义网络</h1><p>对于需要创建自定义逻辑的网络层，可以通过自定义类来实现。在创建自定义网络层 类时，需要继承自 layers.Layer 基类;创建自定义的网络类时，需要继承自 keras.Model 基 类，这样建立的自定义类才能够方便的利用 Layer/Model 基类提供的参数管理等功能，同 时也能够与其他的标准网络层类交互使用。</p>
<h2 id="自定义网络层"><a href="#自定义网络层" class="headerlink" title="自定义网络层"></a>自定义网络层</h2><ul>
<li>对于自定义的网络层，至少需要实现初始化<strong>init</strong>方法和前向传播逻辑 call 方法。</li>
<li>首先创建类，并继承自 Layer 基类。创建初始化方法，并调用母类的初始化函数，由 于是全连接层，因此需要设置两个参数:输入特征的长度 inp_dim 和输出特征的长度 outp_dim，并通过 self.add_variable(name, shape)创建 shape 大小，名字为 name 的张量𝑾， 并设置为需要优化。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span>(<span class="params">layers.Layer</span>):</span> <span class="comment"># 自定义网络层</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inp_dim, outp_dim</span>):</span></span><br><span class="line">		<span class="built_in">super</span>(MyDense, self).__init__()</span><br><span class="line">		<span class="comment"># 创建权值张量并添加到类管理列表中，设置为需要优化</span></span><br><span class="line">		self.kernel = self.add_variable(<span class="string">&#x27;w&#x27;</span>, [inp_dim, outp_dim],</span><br><span class="line">		trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = MyDense(<span class="number">4</span>,<span class="number">3</span>) <span class="comment"># 创建输入为 4，输出为 3 节点的自定义层 </span></span><br><span class="line">net.variables,net.trainable_variables <span class="comment"># 查看自定义层的参数列表</span></span><br></pre></td></tr></table></figure>
<ul>
<li>通过修改为 self.kernel = self.add_variable(‘w’, [inp_dim, outp_dim], trainable=False)，我们可以设置𝑾张量不需要被优化</li>
<li>通过 tf.Variable 创建的类成员也会自动加入类参数列表</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过 tf.Variable 创建的类成员也会自动加入类参数列表</span></span><br><span class="line">self.kernel = tf.Variable(tf.random.normal([inp_dim, outp_dim]),</span><br><span class="line">                trainable=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>自定义类的前向运算逻辑，对于这个例 子，只需要完成𝑶 = 𝑿@𝑾矩阵运算，并通过固定的 ReLU 激活函数即可</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span> </span><br><span class="line">	<span class="comment"># 实现自定义类的前向计算逻辑</span></span><br><span class="line">	<span class="comment"># X@W</span></span><br><span class="line">	out = inputs @ self.kernel</span><br><span class="line">	<span class="comment"># 执行激活函数运算</span></span><br><span class="line">	out = tf.nn.relu(out) <span class="keyword">return</span> out</span><br><span class="line"> </span><br></pre></td></tr></table></figure>
<ul>
<li>自定义类的前向运算逻辑实现在 call(inputs, training=None)函数中，其中 inputs 代表输入，由用户在调用时传入;training 参数用于指定模型的状态:training 为 True 时执 行训练模式，training 为 False 时执行测试模式，默认参数为 None，即测试模式。由于全连 接层的训练模式和测试模式逻辑一致，此处不需要额外处理。对于部份测试模式和训练模 式不一致的网络层，需要根据 training 参数来设计需要执行的逻辑。</li>
</ul>
<h2 id="自定义网络-1"><a href="#自定义网络-1" class="headerlink" title="自定义网络"></a>自定义网络</h2><ul>
<li>自定义网络类可以和其他标准类一样，通过 Sequential 容器方便地封装成一个网络模型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([MyDense(<span class="number">784</span>, <span class="number">256</span>), <span class="comment"># 使用自定义的层 MyDense(256, 128),</span></span><br><span class="line">                 MyDense(<span class="number">128</span>, <span class="number">64</span>),</span><br><span class="line">                 MyDense(<span class="number">64</span>, <span class="number">32</span>),</span><br><span class="line">                 MyDense(<span class="number">32</span>, <span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br></pre></td></tr></table></figure>
<ul>
<li>创建自定义网络类，首先 创建类，并继承自 Model 基类，分别创建对应的网络层对象和前向运算逻辑</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line">	<span class="comment"># 自定义网络类，继承自 Model 基类 </span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">		<span class="built_in">super</span>(MyModel, self).__init__() <span class="comment"># 完成网络内需要的网络层的创建工作 </span></span><br><span class="line">		self.fc1 = MyDense(<span class="number">28</span>*<span class="number">28</span>, <span class="number">256</span>) </span><br><span class="line">		self.fc2 = MyDense(<span class="number">256</span>, <span class="number">128</span>) </span><br><span class="line">		self.fc3 = MyDense(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">		self.fc4 = MyDense(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">		self.fc5 = MyDense(<span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span> <span class="comment"># 自定义前向运算逻辑</span></span><br><span class="line">		x = self.fc1(inputs)</span><br><span class="line">		x = self.fc2(x)</span><br><span class="line">		x = self.fc3(x)</span><br><span class="line">		x = self.fc4(x)</span><br><span class="line">		x = self.fc5(x)</span><br><span class="line">		<span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h1 id="常用模型"><a href="#常用模型" class="headerlink" title="常用模型"></a>常用模型</h1><p>对于常用的网络模型，如 ResNet、VGG 等，不需要手动创建网络，可以直接从 keras.applications 子模块中通过一行代码即可创建并使用这些经典模型，同时还可以通过设 置 weights 参数加载预训练的网络参数。</p>
<h2 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h2><ul>
<li>以 ResNet50 网络模型为例，一般将 ResNet50 去除最后一层后的网络作为新任务的特 征提取子网络，即利用在 ImageNet 数据集上预训练好的网络参数初始化，并根据自定义任 务的类别追加一个对应数据类别数的全连接分类层或子网络，从而可以在预训练网络的基 础上快速、高效地学习新任务。</li>
<li>首先利用 Keras 模型乐园加载 ImageNet 预训练好的 ResNet50 网络</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载 ImageNet 预训练网络模型，并去掉最后一层</span></span><br><span class="line">resnet = keras.applications.ResNet50(weights=<span class="string">&#x27;imagenet&#x27;</span>,include_top=<span class="literal">False</span>) resnet.summary()</span><br><span class="line"><span class="comment"># 测试网络的输出</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>])</span><br><span class="line">out = resnet(x) <span class="comment"># 获得子网络的输出</span></span><br><span class="line">out.shape</span><br></pre></td></tr></table></figure>
<ul>
<li>新建一个池化层(这里的池化层暂时 可以理解为高、宽维度下采样的功能)，将特征从[𝑏, 7,7,2048]降维到[𝑏, 2048]</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建池化层</span></span><br><span class="line">global_average_layer = layers.GlobalAveragePooling2D() <span class="comment"># 利用上一层的输出作为本层的输入，测试其输出</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">7</span>,<span class="number">7</span>,<span class="number">2048</span>])</span><br><span class="line"><span class="comment"># 池化层降维，形状由[4,7,7,2048]变为[4,1,1,2048],删减维度后变为[4,2048] </span></span><br><span class="line">out = global_average_layer(x)</span><br><span class="line">print(out.shape)</span><br></pre></td></tr></table></figure>
<ul>
<li>新建一个全连接层，并设置输出节点数为 100</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建全连接层</span></span><br><span class="line">fc = layers.Dense(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 利用上一层的输出[4,2048]作为本层的输入，测试其输出</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">2048</span>])</span><br><span class="line">out = fc(x) <span class="comment"># 输出层的输出为样本属于 100 类别的概率分布</span></span><br><span class="line">print(out.shape)</span><br></pre></td></tr></table></figure>
<h1 id="测量工具"><a href="#测量工具" class="headerlink" title="测量工具"></a>测量工具</h1><p>在网络的训练过程中，经常需要统计准确率、召回率等测量指标，除了可以通过手动 计算的方式获取这些统计数据外，Keras 提供了一些常用的测量工具，位于 keras.metrics 模 块中，专门用于统计训练过程中常用的指标数据。</p>
<h2 id="新建测量器"><a href="#新建测量器" class="headerlink" title="新建测量器"></a>新建测量器</h2><p>在 keras.metrics 模块中，提供了较多的常用测量器类，如统计平均值的 Mean 类，统 计准确率的 Accuracy 类，统计余弦相似度的 CosineSimilarity 类等。下面我们以统计误差 值为例。在前向运算时，我们会得到每一个 Batch 的平均误差，但是我们希望统计每个 Step 的平均误差，因此选择使用 Mean 测量器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建平均测量器，适合 Loss 数据 </span></span><br><span class="line">loss_meter = metrics.Mean()</span><br></pre></td></tr></table></figure>
<h2 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h2><p>通过测量器的 update_state 函数可以写入新的数据，测量器会根据自身逻辑记录并处理采样数据。例如，在每个 Step 结束时采集一次 loss 值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 记录采样的数据，通过 float()函数将张量转换为普通数值</span></span><br><span class="line">loss_meter.update_state(<span class="built_in">float</span>(loss))</span><br></pre></td></tr></table></figure>
<h2 id="读取统计信息"><a href="#读取统计信息" class="headerlink" title="读取统计信息"></a>读取统计信息</h2><p>在采样多次数据后，可以选择在需要的地方调用测量器的 result()函数，来获取统计值。例如，间隔性统计 loss 均值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 打印统计期间的平均 loss</span></span><br><span class="line">print(step, <span class="string">&#x27;loss:&#x27;</span>, loss_meter.result())</span><br></pre></td></tr></table></figure>
<h2 id="清除状态"><a href="#清除状态" class="headerlink" title="清除状态"></a>清除状态</h2><p>由于测量器会统计所有历史记录的数据，因此在启动新一轮统计时，有必要清除历史 状态。通过 reset_states()即可实现清除状态功能。例如，在每次读取完平均误差后，清零统 计信息，以便下一轮统计的开始。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">	<span class="comment"># 打印统计的平均 loss</span></span><br><span class="line">	print(step, <span class="string">&#x27;loss:&#x27;</span>, loss_meter.result())</span><br><span class="line">	loss_meter.reset_states() <span class="comment"># 打印完后，清零测量器</span></span><br></pre></td></tr></table></figure>
<h2 id="准确率统计实战"><a href="#准确率统计实战" class="headerlink" title="准确率统计实战"></a>准确率统计实战</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">acc_meter = metrics.Accuracy() <span class="comment"># 创建准确率测量器</span></span><br><span class="line"><span class="comment"># [b, 784] =&gt; [b, 10]，网络输出值</span></span><br><span class="line"><span class="comment">#Accuracy 类的 update_state 函数的参数为预测值和真实值，而不是当前 Batch 的准确率</span></span><br><span class="line">out = network(x)</span><br><span class="line"><span class="comment"># [b, 10] =&gt; [b]，经过 argmax 后计算预测值 </span></span><br><span class="line">pred = tf.argmax(out, axis=<span class="number">1</span>)</span><br><span class="line">pred = tf.cast(pred, dtype=tf.int32) <span class="comment"># 根据预测值与真实值写入测量器</span></span><br><span class="line">acc_meter.update_state(y, pred)</span><br><span class="line"><span class="comment"># 读取统计结果</span></span><br><span class="line">print(step, <span class="string">&#x27;Evaluate Acc:&#x27;</span>, acc_meter.result().numpy()) </span><br><span class="line">acc_meter.reset_states() <span class="comment"># 清零测量器</span></span><br></pre></td></tr></table></figure>
<h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><p>TensorFlow 提供了一个专门的可视 化工具，叫做 TensorBoard，它通过 TensorFlow 将监控数据写入到文件系统，并利用 Web 后端监控对应的文件目录，从而可以允许用户从远程查看网络的监控数据。</p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><ul>
<li>通过 tf.summary.create_file_writer 创建监控对象类实例，并指定监控数据的写入目录</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 创建监控类，监控数据将写入 log_dir 目录</span></span><br><span class="line">summary_writer = tf.summary.create_file_writer(log_dir)</span><br></pre></td></tr></table></figure>
<ul>
<li>通过 tf.summary.scalar 函数记录监控数据，并指定时 间戳 step 参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> summary_writer.as_default(): <span class="comment"># 写入环境</span></span><br><span class="line"><span class="comment"># 当前时间戳 step 上的数据为 loss，写入到名为 train-loss 数据库中</span></span><br><span class="line">   tf.summary.scalar(<span class="string">&#x27;train-loss&#x27;</span>, <span class="built_in">float</span>(loss), step=step)</span><br></pre></td></tr></table></figure>
<ul>
<li>通过 tf.summary.image 函数写入监控图片数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> summary_writer.as_default():<span class="comment"># 写入环境</span></span><br><span class="line"><span class="comment"># 写入测试准确率</span></span><br><span class="line">	tf.summary.scalar(<span class="string">&#x27;test-acc&#x27;</span>, <span class="built_in">float</span>(total_correct/total),</span><br><span class="line">	step=step)</span><br><span class="line"><span class="comment"># 可视化测试用的图片，设置最多可视化 9 张图片</span></span><br><span class="line">	tf.summary.image(<span class="string">&quot;val-onebyone-images:&quot;</span>, val_images,</span><br><span class="line">max_outputs=<span class="number">9</span>, step=step)</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/12/04/Tensorflow/Tensorflow-Keras-high-level-interface/" data-id="ckutyt6os004fav0a1rhwfe7a" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/" rel="tag">tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/" rel="tag">深度学习框架</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/12/04/Tensorflow/Tensorflow-and-Convolutional-Neural-Network/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Tensorflow与卷积神经网络
        
      </div>
    </a>
  
  
    <a href="/2020/12/04/Tensorflow/Tensorflow-and-Neural-Networks/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Tensorflow构建简单神经网络</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/PTA%E7%94%B2%E7%BA%A7%E5%88%B7%E9%A2%98/">PTA甲级刷题</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/leetcode%E5%88%B7%E9%A2%98/">leetcode刷题</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/">爬虫学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">论文复现</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/">课程设计</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/c/" rel="tag">c++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/django/" rel="tag">django</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/" rel="tag">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyquery/" rel="tag">pyquery</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch/" rel="tag">pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/springboot/" rel="tag">springboot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/" rel="tag">tensorflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vue/" rel="tag">vue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" rel="tag">动态规划</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E6%BA%AF/" rel="tag">回溯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE/" rel="tag">图</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%9A%E6%96%87%E6%A1%A3%E6%91%98%E8%A6%81/" rel="tag">多文档摘要</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" rel="tag">字符串</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="tag">强化学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="tag">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A0%91/" rel="tag">树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E6%8B%9F/" rel="tag">模拟</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82/" rel="tag">模拟网络请求</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/" rel="tag">深度学习框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90/" rel="tag">网页解析</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/c/" style="font-size: 17.78px;">c++</a> <a href="/tags/django/" style="font-size: 10px;">django</a> <a href="/tags/java/" style="font-size: 14.44px;">java</a> <a href="/tags/pyquery/" style="font-size: 10px;">pyquery</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/pytorch/" style="font-size: 15.56px;">pytorch</a> <a href="/tags/springboot/" style="font-size: 10px;">springboot</a> <a href="/tags/tensorflow/" style="font-size: 16.67px;">tensorflow</a> <a href="/tags/vue/" style="font-size: 11.11px;">vue</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">动态规划</a> <a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size: 10px;">回溯</a> <a href="/tags/%E5%9B%BE/" style="font-size: 10px;">图</a> <a href="/tags/%E5%A4%9A%E6%96%87%E6%A1%A3%E6%91%98%E8%A6%81/" style="font-size: 10px;">多文档摘要</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" style="font-size: 10px;">字符串</a> <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">强化学习</a> <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 13.33px;">操作系统</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 11.11px;">数据库</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 10px;">数据结构</a> <a href="/tags/%E6%A0%91/" style="font-size: 12.22px;">树</a> <a href="/tags/%E6%A8%A1%E6%8B%9F/" style="font-size: 10px;">模拟</a> <a href="/tags/%E6%A8%A1%E6%8B%9F%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82/" style="font-size: 11.11px;">模拟网络请求</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 14.44px;">深度学习</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/" style="font-size: 18.89px;">深度学习框架</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 15.56px;">爬虫</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 17.78px;">算法</a> <a href="/tags/%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90/" style="font-size: 10px;">网页解析</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">十月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/10/16/Arithmetic-LeetCode/282/">282</a>
          </li>
        
          <li>
            <a href="/2020/12/12/Pytorch/Pytorch-Reinforcement-Learning-Algorithm/">Pytorch强化学习算法实现</a>
          </li>
        
          <li>
            <a href="/2020/12/09/Pytorch/PyTorch-Commonly-Used-Tool-Modules/">PyTorch常用工具模块</a>
          </li>
        
          <li>
            <a href="/2020/12/09/Pytorch/Pytorch-and-torch-nn/">Pytorch中神经网络工具箱nn模块</a>
          </li>
        
          <li>
            <a href="/2020/12/09/Pytorch/Pytorch-and-Autograd/">Pytorch中的Autograd</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 ccclll777<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>